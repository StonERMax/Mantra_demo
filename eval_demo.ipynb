{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YqbDFqm-vH9u"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/CyanideBoy/Mantra_demo/blob/master/eval_demo.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "a0XrnhEKvH9z",
    "outputId": "2ee952b6-f127-413b-e934-fb40ecce1a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Mantra_demo'...\n",
      "remote: Enumerating objects: 11, done.\u001b[K\n",
      "remote: Counting objects: 100% (11/11), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 563 (delta 3), reused 0 (delta 0), pack-reused 552\u001b[K\n",
      "Receiving objects: 100% (563/563), 136.69 MiB | 32.72 MiB/s, done.\n",
      "Resolving deltas: 100% (219/219), done.\n",
      "Checking out files: 100% (516/516), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf Mantra_demo\n",
    "!git clone https://github.com/CyanideBoy/Mantra_demo.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 712
    },
    "colab_type": "code",
    "id": "amhozZJwvH99",
    "outputId": "dd1061ff-c6ba-4cb9-9cdc-cbe11036266a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1078140188034994020\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 7824641803535032092\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 13625588030615240786\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2548465663738854049\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11375751988\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 4623123162346270461\n",
      "physical_device_desc: \"device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11990623847\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 5519758876836836918\n",
      "physical_device_desc: \"device: 1, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1\"\n",
      "]\n",
      "4.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0,'Mantra_demo')\n",
    "\n",
    "import numpy as np \n",
    "import cv2 as cv2\n",
    "import lmdb\n",
    "import keras\n",
    "from matplotlib import pyplot\n",
    "np.set_printoptions( 3, suppress = True )\n",
    "from tensorflow.python.client import device_lib\n",
    "from tf_multi_gpu import make_parallel \n",
    "print device_lib.list_local_devices()\n",
    "from keras.utils import to_categorical\n",
    "import modelCore\n",
    "\n",
    "print cv2.__version__\n",
    "fontsize = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9hL5LML4vH-E"
   },
   "outputs": [],
   "source": [
    "debug = False   # Setting it True gives performance similar to what paper reports\n",
    "idx = 1         # Model id (0-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPrpV1ZjvH-L"
   },
   "source": [
    "# Prepare Model and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4fdSzoYvH-L"
   },
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.insert( 0, 'sequence/')\n",
    "\n",
    "manTraNet_root = './Mantra_demo'\n",
    "manTraNet_modelDir = os.path.join( manTraNet_root, 'pretrained_weights' )\n",
    "\n",
    "def get_single_gpu_model(idx) :\n",
    "    \n",
    "    mantra_model = modelCore.load_pretrain_model_by_index( idx, manTraNet_modelDir )\n",
    "    print mantra_model.summary(line_length=120)\n",
    "    \n",
    "    return mantra_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoMSWfgSvH-S"
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TiB3BpJxvH-T"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import tensorflow as tf\n",
    "\n",
    "def np_F1( y_true, y_pred ) :\n",
    "    score = []\n",
    "    for yy_true, yy_pred in zip( y_true, y_pred ) :\n",
    "        this = f1_score( (yy_true>.5).astype('int').ravel(), (yy_pred>.5).astype('int').ravel() )\n",
    "        that = f1_score( (yy_true>.5).astype('int').ravel(), (1-yy_pred>.5).astype('int').ravel() )\n",
    "        score.append( max( this, that ) )\n",
    "    return np.mean( score ).astype('float32')\n",
    "\n",
    "\n",
    "def F1( y_true, y_pred ) :\n",
    "    return tf.py_func( np_F1, [y_true, y_pred], 'float32')\n",
    "\n",
    "def np_auc( y_true, y_pred ) :\n",
    "    score = []\n",
    "\n",
    "    for yy_true, yy_pred in zip( y_true, y_pred ) :\n",
    "        this = roc_auc_score( (yy_true>.5).astype('int').ravel(), yy_pred.ravel() )\n",
    "        that = roc_auc_score( (yy_true>.5).astype('int').ravel(), 1-yy_pred.ravel() )\n",
    "        score.append( max( this, that ) )\n",
    "    return np.mean( score ).astype('float32')\n",
    "\n",
    "def auroc(y_true, y_pred):\n",
    "    return tf.py_func( np_auc, [y_true, y_pred], 'float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bU8eR-GzvH-Z"
   },
   "source": [
    "# Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3CKR0CnTvH-a"
   },
   "outputs": [],
   "source": [
    "def prepare_coverage_dataset() :\n",
    "    input_image_file_list = 'COVERAGE_image_new.list'\n",
    "    #input_image_file_list = os.path.join(manTraNet_root, 'VERAGE')\n",
    "    with open( 'Mantra_demo/' + input_image_file_list, 'r') as IN :\n",
    "        input_files = [ 'Mantra_demo/'+line.strip() for line in IN.readlines() ]\n",
    "    print \"INFO: successfully load\", len( input_files ), \"input files\"\n",
    "\n",
    "    def get_input_ID( input_file ) :\n",
    "        bname = os.path.basename( input_file )\n",
    "        return bname.rsplit('.')[0]\n",
    "\n",
    "    def get_mask_file_from_ID( sample_id ) :\n",
    "        return os.path.join('Mantra_demo/VERAGE/mask/', '{}forged.tif'.format(sample_id[:-1]) ) \n",
    "\n",
    "    def preprocess( input_image, input_mask ) :\n",
    "        x = np.expand_dims( input_image, axis=0 ).astype('float32')/255. * 2 - 1\n",
    "        y = np.expand_dims( np.expand_dims( input_mask, axis=0 ), axis=-1 )/255.\n",
    "        return x, y\n",
    "\n",
    "    raw_lut = dict( zip( [ get_input_ID(f) for f in input_files ], input_files) )\n",
    "\n",
    "    paired_results = []\n",
    "    for key in raw_lut.keys() : \n",
    "        raw_file = raw_lut[key]\n",
    "        mask_file = get_mask_file_from_ID(key)\n",
    "        \n",
    "        r = cv2.imread(raw_file, 1 )[...,::-1]\n",
    "        m = cv2.imread(mask_file, 0)\n",
    "        if r.shape[:2] != m.shape[:2] :\n",
    "            continue\n",
    "        \n",
    "        raw_mask_dec = (raw_file, mask_file )\n",
    "        paired_results.append( raw_mask_dec )\n",
    "\n",
    "    print len(paired_results)\n",
    "    return paired_results, len(paired_results), preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6DSTtQJ_vH-i"
   },
   "source": [
    "# Evaluate model performance for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2vLykZbvH-l"
   },
   "outputs": [],
   "source": [
    "def create_evaluation_data_generator( paired_results, preprocess ) :\n",
    "    for raw_file, mask_file in paired_results :\n",
    "        r = cv2.imread( raw_file, 1 )[...,::-1]\n",
    "        m = cv2.imread( mask_file, 0)\n",
    "        if r.shape[:2] != m.shape[:2] :\n",
    "            print \"INFO: find unmatched\", raw_file, mask_file, \", skip\"\n",
    "            continue\n",
    "        x, y = preprocess( r, m )\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-LFvdXh7vH-p"
   },
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "colab_type": "code",
    "id": "imbMwUhNvH-r",
    "outputId": "9f6a1044-b71b-4846-e439-7a7a8b52f288"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: use activation in the last CONV=None\n",
      "INFO: unfreeze feature extraction part, trainable=True\n",
      "('INFO: freeze', 'image_in')\n",
      "('INFO: freeze', 'b1c1')\n",
      "('INFO: freeze', 'b1c2')\n",
      "('INFO: freeze', 'b2c1')\n",
      "('INFO: freeze', 'b2c2')\n",
      "________________________________________________________________________________________________________________________\n",
      "Layer (type)                           Output Shape               Param #       Connected to                            \n",
      "========================================================================================================================\n",
      "img_in (InputLayer)                    (None, None, None, 3)      0                                                     \n",
      "________________________________________________________________________________________________________________________\n",
      "Featex (Model)                         (None, None, None, 256)    3680989       img_in[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "outlierTrans (Conv2D)                  (None, None, None, 64)     16384         Featex[1][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "bnorm (BatchNormalization)             (None, None, None, 64)     128           outlierTrans[0][0]                      \n",
      "________________________________________________________________________________________________________________________\n",
      "glbStd (GlobalStd2D)                   (None, 1, 1, 64)           64            bnorm[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "nestedAvgFeatex (NestedWindowAverageFe (None, 5, None, None, 64)  0             bnorm[0][0]                             \n",
      "________________________________________________________________________________________________________________________\n",
      "expTime (Lambda)                       (None, 1, 1, 1, 64)        0             glbStd[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "divStd (Lambda)                        (None, 5, None, None, 64)  0             nestedAvgFeatex[0][0]                   \n",
      "                                                                                expTime[0][0]                           \n",
      "________________________________________________________________________________________________________________________\n",
      "cLSTM (ConvLSTM2D)                     (None, None, None, 8)      112928        divStd[0][0]                            \n",
      "________________________________________________________________________________________________________________________\n",
      "pred (Conv2D)                          (None, None, None, 1)      393           cLSTM[0][0]                             \n",
      "========================================================================================================================\n",
      "Total params: 3,810,886\n",
      "Trainable params: 3,744,361\n",
      "Non-trainable params: 66,525\n",
      "________________________________________________________________________________________________________________________\n",
      "None\n",
      "INFO: successfully load 100 input files\n",
      "91\n",
      "91/91 [==============================] - 125s 1s/step\n",
      "COVERAGE {'acc': 0.9024703797403273, 'loss': 0.26143083520806754, 'auroc': 0.8847798508602184, 'F1': 0.42781199926285296}\n",
      "+----------+--------+---------+--------+\n",
      "| Dataset  |  Loss  | Acc/AUC |   F1   |\n",
      "+----------+--------+---------+--------+\n",
      "| COVERAGE | 0.2614 |  0.8848 | 0.4278 |\n",
      "+----------+--------+---------+--------+\n"
     ]
    }
   ],
   "source": [
    "model = get_single_gpu_model(idx)\n",
    "model.compile( optimizer='sgd',\n",
    "               loss ='binary_crossentropy',\n",
    "               metrics=['accuracy', F1, auroc], )\n",
    "\n",
    "\n",
    "from prettytable import PrettyTable\n",
    "import os\n",
    "import json\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = ['Dataset', 'Loss', 'Acc/AUC', 'F1' ]\n",
    "\n",
    "mega_lut = dict()\n",
    "\n",
    "for prepare_dataset, name in zip( [ prepare_coverage_dataset ],\n",
    "                                  ['COVERAGE'] ) :\n",
    "    input_pairs, L, preprocess = prepare_dataset()\n",
    "    # create data generator\n",
    "    datagen = create_evaluation_data_generator( input_pairs, preprocess ) \n",
    "    res = model.evaluate_generator( datagen, L if not debug else 1, verbose=1 )\n",
    "    # print \n",
    "    lut = dict( zip( model.metrics_names, res ) )\n",
    "    print name, lut\n",
    "    mega_lut[name] = lut\n",
    "    # update\n",
    "    table.add_row( [name] + [ \"{:.4f}\".format(lut[key]) for key in ['loss', 'auroc', 'F1'] ] )\n",
    "\n",
    "print (table)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "eval_demo.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
